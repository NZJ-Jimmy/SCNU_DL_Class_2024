{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/pdf/2010.11929.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import einops\n",
    "import copy\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from enum import Enum, auto\n",
    "from collections import defaultdict\n",
    "from IPython.display import HTML\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ViT paper and anwser the following TODO questions\n",
    "### https://arxiv.org/pdf/2010.11929"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data', transform=torchvision.transforms.ToTensor(), download=False, train=True),\n",
    "    batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data', transform=torchvision.transforms.ToTensor(), download=False, train=False),\n",
    "    batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(model, label='test', silent=False):\n",
    "    model.eval()\n",
    "    dataset = data_test if label == 'test' else data\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    for x, y in dataset:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        res = model(x).argmax(-1)\n",
    "        count += len(x)\n",
    "        correct += (res == y).float().sum()\n",
    "    acc = correct / count\n",
    "    if not silent: print(f'accuracy on {label:5}: {acc}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(*args, n_col=None, figsize=None, block_size=3, labels=None):\n",
    "    '''Plot images in a grid\n",
    "    usage: plot(img1, img2, ...)\n",
    "    optional: n_col=3, figsize=(12, 8), block_size=1\n",
    "\n",
    "    img: torch.Tensor of shape (H, W) or (C, H, W) or [(H, W), ...] or [(C, H, W), ...]\n",
    "    '''\n",
    "    imgs = []\n",
    "    for img in args:\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            if img.dim() == 4: imgs.extend([img[i] for i in range(img.shape[0])])\n",
    "            else: imgs.append(img)\n",
    "        if isinstance(img, list) or isinstance(img, tuple):\n",
    "            assert all(isinstance(i, torch.Tensor) and i.dim() == 3 for i in img)\n",
    "            imgs.extend(img)\n",
    "\n",
    "    # flatten channels\n",
    "    imgs = [img.squeeze(0) if img.dim() == 3 else img for img in imgs]\n",
    "    imgs = [img.detach().cpu() for img in imgs]\n",
    "\n",
    "    if n_col is None: n_col = len(imgs)\n",
    "    n_row = math.ceil(len(imgs) / n_col)\n",
    "    if figsize is None: figsize = (n_col * block_size, n_row * block_size)\n",
    "    # normalize ax to 2d array\n",
    "    fig, ax = plt.subplots(n_row, n_col, figsize=figsize)\n",
    "    if n_row == 1 and n_col == 1: ax = np.array([[ax]])\n",
    "    elif n_row == 1: ax = ax.reshape((1, -1))\n",
    "    elif n_col == 1: ax = ax.reshape((-1, 1))\n",
    "    # plot\n",
    "    for i, img in enumerate(imgs):\n",
    "        idx = (i // n_col, i % n_col)\n",
    "        ax[idx].imshow(img)\n",
    "        if labels and i < len(labels): ax[idx].set_title(labels[i])\n",
    "    # remove the axis\n",
    "    for i in range(n_row * n_col):\n",
    "        idx = (i // n_col, i % n_col)\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "        if i >= len(imgs): ax[idx].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test plot function\n",
    "def test_plot(scale=3):\n",
    "    imgs = next(iter(data))[0]\n",
    "    plot(imgs[0], block_size=scale)\n",
    "    plot(imgs[1], imgs[2], block_size=scale)\n",
    "    plot(imgs[3], imgs[4], n_col=scale, block_size=scale)\n",
    "    plot(imgs[5], imgs[6], imgs[7], n_col=2, block_size=scale)\n",
    "    plot(imgs[:5], n_col=3, block_size=scale)\n",
    "\n",
    "# test_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chunk images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "images = next(iter(data))[0][:2]\n",
    "plot(images[0])\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the 4x4 image chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "b, c, h, w = images.shape\n",
    "# cut into tiles\n",
    "tile_size = 7\n",
    "plot(images[0])\n",
    "print(images[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use einops to speed the chunking'\n",
    "### Explain TODO in comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 1, 7, 7])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# cut into tiles\n",
    "tile_size = 7\n",
    "tiles = einops.rearrange(images, 'b c (h t1) (w t2) -> b (h w) c t1 t2', t1=tile_size, t2=tile_size)\n",
    "plot(tiles[0], n_col=4, block_size=1)\n",
    "print(tiles.size())\n",
    "# the tiles have size (Batch, 16=4x4, channel=1, H=7, W=7), that is the tokens are sequential\n",
    "# explain why tiles[0, 5, ...] are equal to images[B=0,C=0,H=7:14,W=7:14]\n",
    "# hint: the tiles[0, 5] is 5-th token of first image in batch, which is the row=1,col=1 token of size 7x7\n",
    "# the image pixels are ?\n",
    "print(tiles[0,5,0,:])\n",
    "print(images[0,0,7:14,7:14])\n",
    "assert torch.allclose(tiles[0,5,0,:],images[0,0,7:14,7:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder parameters\n",
    "### TODO: explain what is the value of context_size and its meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HEADS = 2\n",
    "N_BLOCKS = 2\n",
    "VOCAB_SIZE = 10\n",
    "EMBED_SIZE = 16\n",
    "HIDDEN_SIZE = 32\n",
    "IMG_SIZE = 28\n",
    "CHANNEL = 1\n",
    "TILE_SIZE = 7\n",
    "assert IMG_SIZE % TILE_SIZE == 0\n",
    "CONTEXT_SIZE = 1 + (IMG_SIZE // TILE_SIZE) ** 2\n",
    "LEARNING_RATE = 3e-4\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_SIZE  # why add 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinuoid positional embedding\n",
    "### TODO: refer to Transformer paper and explain the function of the position encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoidal_positional_encoding(context_size=CONTEXT_SIZE, embed_size=EMBED_SIZE):\n",
    "  position = torch.arange(context_size).unsqueeze(1)\n",
    "  div_term = torch.exp(torch.arange(0, embed_size, 2) * -(math.log(10000.0) / embed_size))\n",
    "  positional_encoding = torch.zeros(context_size, embed_size)\n",
    "  positional_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "  positional_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "  return positional_encoding.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Explain each step in MultiheadAttention forward function and associate with the QKV equation\n",
    "### TODO: Explain why self.qkv is one linear function instead of three\n",
    "### TODO: Explain why q,k,v transpose(1,2) and y transpose back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "  def __init__(self, n_heads, embed_size, dropout, n_block=0):\n",
    "    super().__init__()\n",
    "    assert embed_size % n_heads == 0, f'{embed_size=} should be divisible by {n_heads=}'\n",
    "    self.n_heads = n_heads\n",
    "    self.embed_size = embed_size\n",
    "    self.dropout_rate = dropout\n",
    "    self.n_block = n_block  # The No. of this MHA\n",
    "    self.qkv = nn.Linear(embed_size, embed_size * 3, bias=False) # generate Q, K, V all at once\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.ln = nn.LayerNorm(embed_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    B, C, E = x.shape\n",
    "    # pre-layernorm\n",
    "    x = self.ln(x)\n",
    "    q, k, v = self.qkv(x).chunk(3, dim=-1)\n",
    "    # split heads\n",
    "    q = q.view(B, C, self.n_heads, self.embed_size // self.n_heads).transpose(1, 2)\n",
    "    k = k.view(B, C, self.n_heads, self.embed_size // self.n_heads).transpose(1, 2)\n",
    "    v = v.view(B, C, self.n_heads, self.embed_size // self.n_heads).transpose(1, 2)\n",
    "    # compute QKV\n",
    "    correlation = q @ k.transpose(-2, -1)\n",
    "    correlation = correlation / math.sqrt(k.shape[-1])\n",
    "    correlation = F.softmax(correlation, dim=-1)\n",
    "    correlation = F.dropout(correlation, p=self.dropout_rate, training=self.training)\n",
    "    y = correlation @ v\n",
    "    # combine heads\n",
    "    y = y.transpose(1, 2).contiguous().view(B, C, self.embed_size)\n",
    "    y = self.dropout(y)\n",
    "    return y\n",
    "\n",
    "  def forward_visualize(self, x):\n",
    "    B, C, E = x.shape\n",
    "    # pre-layernorm\n",
    "    x = self.ln(x)\n",
    "    q, k, v = self.qkv(x).chunk(3, dim=-1)\n",
    "    # split heads\n",
    "    q = q.view(B, C, self.n_heads, self.embed_size // self.n_heads).transpose(1, 2)\n",
    "    k = k.view(B, C, self.n_heads, self.embed_size // self.n_heads).transpose(1, 2)\n",
    "    v = v.view(B, C, self.n_heads, self.embed_size // self.n_heads).transpose(1, 2)\n",
    "    # by hand\n",
    "    correlation = q @ k.transpose(-2, -1)\n",
    "    correlation = correlation / math.sqrt(k.shape[-1])\n",
    "    correlation = F.softmax(correlation, dim=-1)\n",
    "    correlation = F.dropout(correlation, p=self.dropout_rate, training=self.training)\n",
    "    y = correlation @ v\n",
    "    # combine heads\n",
    "    y = y.transpose(1, 2).contiguous().view(B, C, self.embed_size)\n",
    "    y = self.dropout(y)\n",
    "    return y, correlation\n",
    "\n",
    "class Block(nn.Module):\n",
    "  def __init__(self, n_heads, embed_size, hidden_size, dropout, n_block):\n",
    "    super().__init__()\n",
    "    self.block = n_block\n",
    "    self.attention = MultiheadAttention(n_heads, embed_size, dropout=dropout, n_block=n_block)\n",
    "    self.ff = nn.Sequential(\n",
    "      nn.LayerNorm(embed_size), # pre-layernorm\n",
    "      nn.Linear(embed_size, hidden_size),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_size, embed_size),\n",
    "      nn.Dropout(dropout)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.attention(x)\n",
    "    x = x + self.ff(x)\n",
    "    return x\n",
    "  \n",
    "  def forward_visualize(self, x):\n",
    "    x1, cor = self.attention.forward_visualize(x)\n",
    "    x = x + x1\n",
    "    x = x + self.ff(x)\n",
    "    return x, cor\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: explain what is the size and functionality of tile_embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self, n_heads=N_HEADS, n_blocks=N_BLOCKS, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, vocab_size=VOCAB_SIZE, context_size=CONTEXT_SIZE, dropout=DROPOUT, tile_size=TILE_SIZE):\n",
    "    super().__init__()\n",
    "    self.context_size = context_size\n",
    "    self.tile_size = tile_size\n",
    "    # net\n",
    "    self.positional_embedding = get_sinusoidal_positional_encoding()\n",
    "    self.tile_embedding = nn.Linear(TILE_SIZE * TILE_SIZE * CHANNEL, embed_size)\n",
    "    self.cls_token = nn.Parameter(torch.randn(1, 1, embed_size))\n",
    "    self.blocks = nn.Sequential(*[Block(n_heads, embed_size, hidden_size, dropout, i) for i in range(n_blocks)])\n",
    "    self.head = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # (batch_size, channel, height, width)\n",
    "    # split into tiles/patches/chunks\n",
    "    x = einops.rearrange(x, 'b c (h t1) (w t2) -> b (h w) (c t1 t2)', t1=self.tile_size, t2=self.tile_size)\n",
    "    # embed\n",
    "    x = self.tile_embedding(x)\n",
    "    # add cls token\n",
    "    cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "    x = torch.cat((cls_token, x), dim=1)\n",
    "    # positional encoding\n",
    "    x = x + self.positional_embedding\n",
    "    # attention and ff\n",
    "    x = self.blocks(x)\n",
    "    # head\n",
    "    x = self.head(x)\n",
    "    # only look at first token:\n",
    "    x = x[:, 0, :]\n",
    "    return x\n",
    "  \n",
    "  def forward_visualize(self, x):\n",
    "    # (batch_size, channel, height, width)\n",
    "    # split into tiles/patches/chunks\n",
    "    x = einops.rearrange(x, 'b c (h t1) (w t2) -> b (h w) (c t1 t2)', t1=self.tile_size, t2=self.tile_size)\n",
    "    # embed\n",
    "    x = self.tile_embedding(x)\n",
    "    # add cls token\n",
    "    cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "    x = torch.cat((cls_token, x), dim=1)\n",
    "    # positional encoding\n",
    "    x = x + self.positional_embedding\n",
    "    all_corrs = []\n",
    "    for block in self.blocks:\n",
    "      x, corr = block.forward_visualize(x)\n",
    "      all_corrs.append(corr.detach())\n",
    "    \n",
    "    x = self.head(x)\n",
    "    # only look at first token:\n",
    "    x = x[:, 0, :]\n",
    "    return x, all_corrs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Draw outline of this ViT, including the exact number of blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(n_heads=2, n_blocks=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resume training if you want\n",
    "# model.load_state_dict(torch.load('weights/vit_mnist_epoch20.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you don't have a GPU, borrow one checkpoint file from your classmate, and skip the training steps\n",
    "### If you have a 4060 or better GPU, try running for 50 steps or more, and check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n",
      "torch.Size([128, 17, 16]) 2 torch.Size([128, 17, 16]) ---0\n",
      "torch.Size([128, 2, 17, 8]) ---1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     13\u001b[0m   X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m   loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(out, Y)\n\u001b[1;32m     16\u001b[0m   opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/software/anaconda3/envs/videollava/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[38], line 25\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# attention and ff\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# head\u001b[39;00m\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/videollava/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/software/anaconda3/envs/videollava/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/videollava/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[37], line 69\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 69\u001b[0m   x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m   x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff(x)\n\u001b[1;32m     71\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/software/anaconda3/envs/videollava/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[37], line 26\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# by hand\u001b[39;00m\n\u001b[1;32m     25\u001b[0m correlation \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m correlation \u001b[38;5;241m=\u001b[39m correlation \u001b[38;5;241m/\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m correlation \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(correlation, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m correlation \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(correlation, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training steps\n",
    "\n",
    "epochs = 31   # feel free to change to 100 \n",
    "lr = LEARNING_RATE\n",
    "model.train()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "log_every = 2\n",
    "save_every = 10\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for X, Y in data:\n",
    "    X, Y = X.to(device), Y.to(device)\n",
    "    out = model(X)\n",
    "    loss = F.cross_entropy(out, Y)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "  if epoch % log_every == 0:\n",
    "    # print loss\n",
    "    print(f'{epoch:5} {loss.item()}')\n",
    "  \n",
    "  if epoch>5 and epoch % save_every == 0:\n",
    "    # save model\n",
    "    torch.save(model.state_dict(), 'weights/vit_mnist_epoch%02d.pt' % (epoch,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Wait for training finished, or you can interrupt, and load a saved model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('weights/vit_mnist_epoch30.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set accuracy\n",
    "_ = accuracy(model)\n",
    "# train set accuracy\n",
    "_ = accuracy(model, label='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def failing(model, ds=data_test):\n",
    "    model.eval()\n",
    "    misslabeled_imgs = []\n",
    "    losses = []\n",
    "    wrong_labels = []\n",
    "    real_labels = []\n",
    "    for x, y in ds:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        out = logits.argmax(-1)\n",
    "        losses.append(-logits.softmax(1)[torch.arange(logits.shape[0]), y].log()[out != y])\n",
    "        misslabeled_imgs.append(x[out != y])\n",
    "        wrong_labels.append(out[out != y])\n",
    "        real_labels.append(y[out != y])\n",
    "    return torch.cat(misslabeled_imgs), torch.cat(wrong_labels), torch.cat(real_labels), torch.cat(losses)\n",
    "\n",
    "def sorted_failing(model, ds=data_test, descending=True):\n",
    "    imgs, wrong_labels, real_labels, losses = failing(model, ds)\n",
    "    order = losses.argsort(descending=descending)\n",
    "    return imgs[order], wrong_labels[order], real_labels[order], losses[order]\n",
    "\n",
    "def plot_failing(imgs, wrong_labels, real_labels, n_col=7, figsize=(12, 4)):\n",
    "    fig, ax = plt.subplots(2, n_col, figsize=figsize)\n",
    "    \n",
    "    for i in range(imgs.shape[0]):\n",
    "        idx = (i // n_col, i % n_col)\n",
    "        img = imgs[i].cpu().permute(1, 2, 0)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].set_title(f'p={wrong_labels[i].item()} / {real_labels[i].item()} loss={losses[i].item():.2f}')\n",
    "        ax[idx].set_xticks([])\n",
    "        ax[idx].set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "misslabeled_imgs, wrong_labels, real_labels, losses = sorted_failing(model)\n",
    "plot_failing(misslabeled_imgs[:14], wrong_labels[:14], real_labels[:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix\n",
    "### TODO: We want to know which classes are misclassified the most.\n",
    "### TODO: Provide top-5 cases, that True class A is misclassified as B.  Print A->B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def label_all(model, ds=data_test):\n",
    "    model.eval()\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    for x, y in ds:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x).argmax(-1)\n",
    "        predicted_labels.append(out)\n",
    "        real_labels.append(y)\n",
    "    return torch.cat(predicted_labels), torch.cat(real_labels)\n",
    "\n",
    "def to_confusion_matrix(predicted_labels, real_labels):\n",
    "    confusion_matrix = torch.zeros((10, 10), dtype=torch.int32)\n",
    "    for p, r in zip(predicted_labels, real_labels):\n",
    "        confusion_matrix[r, p] += 1\n",
    "    return confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, figsize=(5, 4)):\n",
    "    num_classes = confusion_matrix.shape[0]\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(confusion_matrix, interpolation='nearest', cmap='Blues', norm=colors.LogNorm())\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            plt.text(j, i, int(confusion_matrix[i, j]),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if confusion_matrix[i, j] > confusion_matrix.max() / 2. else \"black\")\n",
    "    plt.title('confusion matrix')\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('real')\n",
    "    plt.xticks(np.arange(num_classes))\n",
    "    plt.yticks(np.arange(num_classes))\n",
    "    plt.show()\n",
    "\n",
    "predicted_labels, real_labels = label_all(model)\n",
    "confusion_matrix = to_confusion_matrix(predicted_labels, real_labels)\n",
    "plot_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize attention\n",
    "### TODO: what do you find the activation map?  \n",
    "### Display one digit as exmample and explain which token i is mostly associated with token j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_attention(model, img):\n",
    "    model.eval()\n",
    "    plot(img)\n",
    "    tiles = einops.rearrange(img, 'c (h t1) (w t2) -> (h w) c t1 t2', t1=TILE_SIZE, t2=TILE_SIZE)\n",
    "    plot(tiles, n_col=4, block_size=0.75)\n",
    "    img = img.to(device).unsqueeze(0)\n",
    "    out, activations = model.forward_visualize(img)\n",
    "    out = out.argmax(-1).item()\n",
    "\n",
    "    plt.gca().axes.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    for block, acts in enumerate(activations):\n",
    "        # 17x17 attention magnitude\n",
    "        #print(acts.size())\n",
    "        acts = acts.squeeze()\n",
    "        acts = acts[1:,1:].cpu()\n",
    "        plt.imshow(acts)\n",
    "        \n",
    "visualize_attention(model, next(iter(data))[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize positional embeddings\n",
    "#### note that emb is (1 + patch_number) * embed_size\n",
    "#### we discard the first [cls], then visualize patch_number*embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_positional_embeddings(emb):\n",
    "    print(emb.size())\n",
    "    # strip cls token\n",
    "    emb = emb[1:]\n",
    "    emb = einops.rearrange(emb, 'n (k1 k2) -> n 1 k1 k2', k1=4)\n",
    "    plot(emb, n_col=4, block_size=1)\n",
    "\n",
    "visualize_positional_embeddings(model.positional_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videollava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
